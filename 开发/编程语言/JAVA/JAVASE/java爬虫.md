1. 网页采用ajax等动态交互模式 爬取的信息可能只有一个div,没有内容，要经过浏览器动态加载后才会显示本来面目
2. 网页采用js等浏览器渲染模式，爬取的信息都是看不懂的，需要浏览器本身来解析成可看的内容
3. 登陆验证：无法直接爬取网站信息，需要模拟浏览器访问网站才可
4. 同一个ip访问一个网站频率太高，被检测出爬虫，直接封杀，所以你得让你的爬虫sleep一下，比如模拟人的规律5分钟爬取一次

1. HttpClient请求
2. 连接池并发
3. 线程池并发
4. 正则表达式
5. IO流保存本地文件

1. 建立网络连接，爬取数据
2. 建立正则表达式规范
3. 使用正则表达式爬取获得的数据

